version: '3'


services:

  socket_producer:
    image: socket_producer
    container_name: socket_producer
    restart: always
    environment:
        - PORT=12345
    build:
      context: ./producers
      dockerfile: Dockerfile
    networks:
      - spark_learning
    volumes:
      - "./producers/src:/app"
    ports:
      - "12345:12345"
    entrypoint: "python -u socket_producer.py"

  postgres:
    image: postgres:${POSTGRES_VERSION}
    container_name: postgres
    restart: always
    environment:
      - "TZ=Europe/Amsterdam"
      - "POSTGRES_USER=docker"
      - "POSTGRES_PASSWORD=docker"
      - spark_learning
    volumes:
      - "./sql:/docker-entrypoint-initdb.d"
    ports:
      - "15432:5432"
    networks:
      - spark_learning

  scylladb:
    image: scylladb/scylla:${SCYLLA_VERSION}
    container_name: scylladb
    restart: always
    environment:
      - "CASSANDRA_CLUSTER_NAME=OUR_DOCKERIZED_CASSANDRA_SINGLE_NODE_CLUSTER"
    ports:
      - "7000:7000"
      - "9042:9042"
    networks:
      - spark_learning

  zookeeper:
    image: confluentinc/cp-zookeeper:${ZOOKEEPER_VERSION}
    hostname: zookeeper
    container_name: zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - spark_learning
    healthcheck:
      test: [ "CMD", "nc", "-z", "zookeeper", "2181" ]
      timeout: 45s
      interval: 10s
      retries: 10

  kafka:
    image: confluentinc/cp-kafka:${KAFKA_VERSION}
    hostname: kafka
    container_name: kafka
    restart: always
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
    networks:
      - spark_learning
    depends_on:
      - zookeeper
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: '1G'
        reservations:
          cpus: '0.5'
          memory: '512M'
    healthcheck:
      test: [ "CMD", "nc", "-z", "kafka", "9092" ]
      timeout: 45s
      interval: 10s
      retries: 10

  control-center:
    image: confluentinc/cp-enterprise-control-center:${CONTROL_CENTER_VERSION}
    hostname: control-center
    container_name: control-center
    networks:
      - spark_learning
    restart: always
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092,localhost:9093'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      PORT: 9021
    healthcheck:
      test: [ "CMD", "nc", "-z", "control-center", "9021" ]
      timeout: 45s
      interval: 10s
      retries: 10
    depends_on:
      - kafka
      - zookeeper

networks:
  spark_learning:
    driver: bridge
